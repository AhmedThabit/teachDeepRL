




Teacher algorithms for curriculum learning of Deep RL in continuously parameterized environments
==================================

TODO add paper link and how to cite citation 

##### Table of Contents  
**[Installation](#installation)**<br>
**[Launch experiments](#launch-experiments)**<br>
**[Visualizations](#visualizations)**<br>

# Installation

1- Get the repository
```
git clone https://github.com/flowersteam/teachDeepRL
cd teachDeepRL/
```
2- Install it, using Conda for example (use Python >= 3.6)
```
conda create --name teachDRL python=3.6
conda activate teachDRL
pip install -e .
```

## Launching experiments

#### Testing teachers on toy env

Test Random, RIAC, ALP-GMM and CovarGMM teachers on a simple toy env
```
cd teachDeepRL/
python3 toy_env/toy_env.py
```
Gifs of the parameter sampling dynamics of teachers will be created in toy_env/gifs/

#### Testing teachers paired with Soft-Actor Critic on Parameterized Bi

First you can visualize the different walkers morphologies along with the tested parametric variations of the environment
 (Stump Tracks and Hexagon Tracks)
 ```
 python3 test_bipedal_walker_continuous.py
 ```
Then you can launch teachers (paired with SAC) on Stump Tracks:
```
python3 run.py --exp_name test_alpgmm --teacher ALP-GMM --seed 42 --leg_size default --max_stump_h 3.0 --max_obstacle_spacing 6.0
```
Available teachers (-- teacher): ALP-GMM, RIAC, Oracle, Random, Covar-GMM
Available walker morphologies (--leg_size): short, default, quadru

You can also test the quadrupedal walker on Hexagon Tracks:
```
python3 run.py --exp_name test_alpgmm_hexa --teacher ALP-GMM --seed 42 --leg_size quadru -hexa 
```

To run multiple seeds, we recommand to use taskset to bind each process to a single cpu thread, like so:
```
taskset -c 0 python3 run.py --exp_name test_alpgmm_hexa --teacher ALP-GMM --seed 42 --leg_size quadru -hexa &
taskset -c 1 python3 run.py --exp_name test_alpgmm_hexa --teacher ALP-GMM --seed 43 --leg_size quadru -hexa &
```
# Visualizations

## Abstract

We consider the problem of how a teacher algorithm can enable an unknown Deep Reinforcement Learning (DRL) student to become
good at a skill over a wide range of diverse environments. To do so, we study how a teacher algorithm can learn to generate 
a learning curriculum, whereby it sequentially samples parameters controlling a stochastic procedural generation of environments.
Because it does not initially know the capacities of its student, a key challenge for the teacher is to discover which environments
are easy, difficult or unlearnable, and in what order to propose them to maximize the efficiency of learning over the learnable ones.
To achieve this, this problem is transformed into a surrogate continuous bandit problem where the teacher samples environments 
in order to maximize absolute learning progress of its student. We present a new algorithm modeling absolute learning progress
with Gaussian mixture models (ALP-GMM). We also adapt existing algorithms and provide a complete study in the context of DRL.
 Using parameterized variants of the BipedalWalker environment, we study their efficiency to personalize a learning curriculum
 for different learners (embodiments), their robustness to the ratio of learnable/unlearnable environments, and their scalability
  to non-linear and high-dimensional parameter spaces.


# Additional Visualizations


## Stump Tracks
We tested the ALP-GMM teacher when paired with 3 different walker morphologies. For each of these walkers we show the
learned walking gates after being trained on a curriculum generated by ALP-GMM. A single run of ALP-GMM allows to train
 Soft Actor-Critic controllers to master a wide range of track distributions.
 
####  ALP-GMM + SAC with short walker (left), default walker (middle) and quadrupedal walker (right)

<p><img src="graphics/readme_graphics/walker_gates/demo_short_stump_gmm_asquad_0.gif" width="32%" height="32%"/>
<img src="graphics/readme_graphics/walker_gates/demo_default_stump_gmm_asquad_0.gif" width="32%" height="32%"/>
<img src="graphics/readme_graphics/walker_gates/demo_quadru_stump_gmm_compact_0.gif" width="32%" height="32%"/></p>

<p><img src="graphics/readme_graphics/walker_gates/demo_short_stump_gmm_asquad_3.gif" width="32%" height="32%"/>
<img src="graphics/readme_graphics/walker_gates/demo_default_stump_gmm_asquad_1.gif" width="32%" height="32%"/>
<img src="graphics/readme_graphics/walker_gates/demo_quadru_stump_gmm_compact_3.gif" width="32%" height="32%"/></p>

<p><img src="graphics/readme_graphics/walker_gates/demo_short_stump_gmm_asquad_2.gif" width="32%" height="32%"/>
<img src="graphics/readme_graphics/walker_gates/demo_default_stump_gmm_asquad_2.gif" width="32%" height="32%"/>
<img src="graphics/readme_graphics/walker_gates/demo_quadru_stump_gmm_compact_2.gif" width="32%" height="32%"/></p>

<p><img src="graphics/readme_graphics/walker_gates/demo_short_stump_gmm_asquad_1.gif" width="32%" height="32%"/>
<img src="graphics/readme_graphics/walker_gates/demo_default_stump_gmm_asquad_3.gif" width="32%" height="32%"/>
<img src="graphics/readme_graphics/walker_gates/demo_quadru_stump_gmm_compact_1.gif" width="32%" height="32%"/></p>

The following videos show the evolution of parameter sampling by ALP-GMM for short, default, and quadrupedal walkers.
Learning curricula generated by ALP-GMM are tailored to the capacities of each student it is paired with.

####  ALP-GMM with short walker (left), default walker (middle) and quadrupedal walker (right)
<p><img src="graphics/readme_graphics/GMM_gmmcshortcpu21-0611.gif" width="32%" height="32%"/>
<img src="graphics/readme_graphics/GMM_gmmcdefaultcpu21-063.gif" width="32%" height="32%"/>
<img src="graphics/readme_graphics/GMM_gmmclongcpu21-060.gif" width="32%" height="32%"/></p>



## Hexagon Tracks
To assess whether ALP-GMM is able to scale to parameter spaces of higher dimensionality, containing irrelevant
 dimensions, and whose difficulty gradients are non-linear, we performed experiments with quadrupedal walkers on Hexagon Tracks,
  our 12-dimensional parametric Bipedal Walker environment. The following videos shows walking gates learned in a single ALP-GMM run.
<p><img src="graphics/readme_graphics/walker_gates/stump_gmm_demo_26.gif"/></p>

<p><img src="graphics/readme_graphics/walker_gates/stump_gmm_demo_compact_3.gif" width="32%" height="32%"/>
<img src="graphics/readme_graphics/walker_gates/stump_gmm_demo_compact_8.gif" width="32%" height="32%"/>
<img src="graphics/readme_graphics/walker_gates/stump_gmm_demo_compact_10.gif" width="32%" height="32%"/></p>

<p><img src="graphics/readme_graphics/walker_gates/stump_gmm_demo_compact_19.gif" width="32%" height="32%"/>
<img src="graphics/readme_graphics/walker_gates/stump_gmm_demo_compact_48.gif" width="32%" height="32%"/>
<img src="graphics/readme_graphics/walker_gates/stump_gmm_demo_compact_36.gif" width="32%" height="32%"/></p>
